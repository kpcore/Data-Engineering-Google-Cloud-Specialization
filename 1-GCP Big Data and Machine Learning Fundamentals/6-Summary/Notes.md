## 1. Summary

* You've made it to the end. We hope you had fun learning new and innovative approaches to solving some of the toughest big data and machine learning challenges out there. Let's do a brief review of what you've learned in this course. At the end, I'll also recommend the next courses and labs you should take on your big data journey with GCP. We first learned that Google technologies are based on really fast networking speeds at the petabit per second level. You no longer need to do everything on a single machine or single cluster of machines with their own dedicated storage. If every machine can talk to every other machine at 10 gigabits per second, backs don't matter for data analytics and ML training. You then saw Google technologies grow and mature as the internet has grown. This suite of Google's solutions is available to you as part of Google Cloud Platform. You explored which tools are used by which data roles in your organization; from analysts, data engineers, ML engineers, and Tech Leads, and which of the core Big Data challenges each role was likely to face. You practiced in your hands-on labs, how to migrate existing workloads to the Cloud with your Spark ML job, analyzing large datasets at scale with BigQuery, building streaming data pipelines with Cloud Dataflow, and applying machine learning throughout the course on both structured and unstructured datasets. You learned where and when to use the fundamental big data products and services to build streaming data pipelines into your data warehouse for machine learning. You learned that Cloud Dataproc can provide flexibility and scalability for your Hadoop workloads without the need for cluster management. You saw the ease in which you can resize your clusters as you need to meet workload demands. Then, we introduced the challenges of streaming data pipelines which come from a variety of different data sources and at large volumes. You also have to solve for streaming data, and building an architecture around receiving and publishing distributed IoT device messages into your pipeline. You saw and built an end-to-end architecture for solving those streaming pipeline changes. You learned that Cloud Pub/Sub receives those messages in a Pub/Sub topic, and is then able to publish them to subscribers, one of which is Cloud Dataflow for ingestion and transformation into BigQuery for analysis and downstream visualization. You explored real customer use cases like Go-Jek, who uses GCP to bring goods and services to over two million families in Indonesia. You built custom machine-learning models on your structured datasets with BigQuery ML. Recall the four key steps; collect, clean, and transform the data, create your model, and select a model type, evaluate model performance, and finally predict with the model on unknown data. We reviewed how to choose an appropriate model type for BigQuery ML based on your use case. We focused primarily on forecasting and classification, where you use linear regression and logistic regression models. Lastly, we reviewed the three main approaches to an AI strategy for your organization and projects. You can leverage the AI building blocks like, Cloud Vision and Natural Language, and you saw how we could extend them with our own data by using AutoML for custom model with no code required. We hope after taking this course, you have gotten a taste for some of the real world big data applications you can tackle for your next project. We'll provide resources at the end of the course on each of the topics covered, and what the subsequent courses are that we recommend for you to take to dive deeper in your knowledge of Google Cloud Platform. This fundamentals course is just the start to your big data journey. If you want to deep dive into BigQuery for data analysis, check out our specialization called from data to insights with GCP. If you want to continue building on your knowledge of pipelines, try data engineering with GCP. If you are ready for custom ML model building with TensorFlow, try our ML on GCP, and advanced ML on GCP specializations that I will link to. Lastly, there are over 200 self-paced labs like the ones you took in this course for additional practice.

## Module Resources

### Blog Post: Building a Data Science team

https://towardsdatascience.com/how-to-hire-a-machine-learning-team-b8055fff57f

https://hackernoon.com/top-10-roles-for-your-data-science-team-e7f05d90d961