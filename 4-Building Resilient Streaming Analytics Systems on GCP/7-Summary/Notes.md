## 1. Course Summary

* You have all made it to the end of this course on streaming analytics pipelines. Let's recap what you have learned. We started off with what streaming data is and the challenges associated with processing streaming data. We said it was important to be able to ingest variables volumes because you could have spikes in your data. It is important to be able to deal with latency because latency is a fact of life. We want to be able to derive real-time insights from the data even as the data are swimming in. In order to do that, we look at the architecture that consisted of ingesting the data with Pub/Sub. Processing the data in stream using Cloud Dataflow. And swimming it into BigQuery for durable storage and interactive analysis. We also spent time talking about how BigTable is a better solution when a much higher throughput is desired. And finally, we went back to BigQuery to look at some of its advanced analysis capabilities with window function and GIS functionalities. As well as reviewed ways to optimize query performance.