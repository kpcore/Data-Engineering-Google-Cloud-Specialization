## 1. Why Auto ML?

* Hello and welcome to the course Custom Model Building with Cloud AutoML. Cloud AutoML is a service on Google Cloud platform that allows you to build powerful machine learning models with minimal effort and machine learning expertise. They're ideal when you have a need to get a machine learning model of the ground as quickly as possible. In this course, we're going to dive into some of the Cloud AutoML products. Auto ML Vision is for image data. NLP is for text based data and Tables is for tabular data. First, let's start off by making the case for why you may want to use AutoML. Where does AutoML sit in the suite of GCP products that can be used for machine learning? On one hand, with products such as Cloud AI platform and BigQuery ML, you can build very customized machine learning models. However, to use these products you will need someone with machine learning expertise and coding experience. You'll be responsible for training the machine learning model yourself, which can take a lot of time. On the other hand on GCP, you can call pre-trained models using services like Cloud Vision API and Cloud speech API. No model training is required for these services. You simply feed the API your data and it returns predictions. The downside of using pre-trained models is that they only yield good predictions when your data is relatively commonplace as in social media images or customer reviews. Cloud AutoML sits somewhere in between these two. A model is trained specific to your data, but you don't need any code to train it. If you're going to train a machine learning model from scratch you need machine learning and coding expertise. Anecdotally, building machine learning models follows the Pareto Principle where you can launch a functional machine learning model relatively quickly. However, most of the time and effort will go into debugging and making the machine learning model perform it. Cloud AutoML follows a standard procedure that is divided into three phases, train, deploy, and serve. The training phase has several steps. First, you have to prepare a data set that will be used in the supervised training process. Next, you need to analyze the data set to make sure it has qualities that will enable it to be effective. After the data set is prepared and validated, you use it to train the model. Finally, the model is used with test data to evaluate whether it is going to be effective in predicting and classifying new cases. If the model doesn't work, well at this point you may have to go back and modify the data set and try again. The second phase is to deploy the model and manage it. That means getting rid of old or unused models. The third phase is hosting the model on a service where it can be used to predict and classify. In traditional machine learning, the deploy and serve phases are complicated and involve moving the model from the model building system, like TensorfFow, to a model hosting system like Cloud ML Engine. However, Cloud AutoML handles most of the complexity of these activities for you making these activities easy. Cloud AutoML uses a prepared data set to train a custom model. You can make small prepared datasets for experimentation directly in the web UI but it is more common to assemble the information in a CSV comma separated value file. The CSV file must be utf-8 encoded and located in the same cloud storage bucket as the source files. You can also create and manage prepared datasets programmatically in Python, Java, or Node.js. The first column in the CSV file is optional. It assigns the data in each row into one of the three groups, train, validation, or test. If you leave out this column, the rows will automatically be assigned with 80% going to train, 10% going to each validation and test. The next column in the CSV file identifies source files that are hosted in cloud storage. These are paths beginning with GS colon slash slash. The source file format depends on the kind of model you are training but can also be compressed zip files. Subsequent columns specify labels. The labels are alphanumeric and can contain underscores but not special characters. The CSV file should not contain duplicate lines and may not contain blank lines or Unicode characters. Currently the CSV file and all the source files must be in a cloud storage bucket in the same project where AutoML runs. Prepared data sets do not expire. You may accumulate many prepared data sets in a project. You can list and delete those that you do not need. Cloud AutoML performs basic checks and a preliminary analysis of the prepared data set to determine if there is enough information and if it is organized properly. If the prepared data set is not ready, you will need to add more rows or more labels to the CSV file. When it is ready, you can start training. Training can take from ten minutes to several hours depending on the kind of model. You can check the status while it's running. Import and training tasks can be cancelled. The trained group of data is used to train the custom model. The source files have already been associated with the correct labels in the prepared data set. So Cloud AutoML uses a supervised learning method to train the custom model. Part of the process uses the validation group data to verify how well the model works at classifying and predicting. Supervised learning works on correctable error. Cloud AutoML constructs an algorithm that guesses the labels for source data. When the guess is right, it strengthens the algorithm. When the guess is wrong, the error is used to correct the algorithm. And this is how learning occurs. One full run through all the trained group data is called an epoch. Total error is track and minimized through multiple epochs to create the best model possible from the training data provided. The result is a trained custom model. The custom model works well with the training data, but is it good at categorizing new instances of data it has not seen before? Data from the test group is used to evaluate the custom model and to remove bias from the evaluation. The predictions and classifications are compared with the labels in the prepared data set. The evaluation report provides indicators that are specific to the kind of model and help understand how effective the model is at predicting and classifying. There is nothing you need to do to activate a model. However, if it has been some time since you used a model, the system may need to warm up for a few minutes before the model becomes active. Once it exists, if you have the project credentials and model name, you can access and use the custom model. Each time you train with a prepared data set it creates a new custom model. You can list and delete unneeded models. Custom models are temporary. They are eventually deleted and they cannot be exported or saved externally. Models that are not used for prediction are automatically deleted after a period of time. Models that are used are eventually deleted. So you will need to train a new custom model periodically to continue predicting and classifying. How long models remain before they are deleted depends on the model type. The primary classification interface is at the URI shown. You can make a classification using the web UR or from the command line using CURL to send a Json structured request. There are also client libraries for Python, Java, and Node.js. After you have set up authentication to use the REST API, you send a request with the model name and the payload, which is the data you want classified. The service returns Json containing multiple fields called displayName. These are the labels that matched. Then it contains the keyword classification followed by a score. The score is a confidence value where 1.0 is absolute confidence and lower fractional numbers represent lower confidence in the correctness of the classification. Quotas apply for both model creation and service requests. Cloud AutoML lowers the effort required to create a model when compared to traditional machine learning. With traditional ML, models were hard to create so there was a tendency to try to make the data set and model all inclusive. With Cloud AutoML you can create smaller more specialized custom models and use them programmatically. So you don't have to squeeze everything into one model. You can break apart a classification into multiple steps. And you can use the results of one classification to make choices about what kind of classification to perform next. Here's an example. A company that sells clothing has a service office that receives emails from customers. The first job might be to distinguish email containing feedback about products from emails requesting information about the company. Model 1 could be used to classify feedback email. The second job might be to distinguish whether the email is describing pants, shirts, shoes, or hats. This might be the job of mode 2. Model 3 might be used only for emails talking about shirts to see if the style of the shirt is mentioned. Model 4 might be used only for emails about shoes to see if the shoe style is mentioned. You can see from this example that a collection of models might be able to accomplish magic in your own application by focusing the scope and purpose of these models. You can also programmatically combine your custom model with a standard model such as Cloud Natural Language API. When should you use cloud AutoML? The recommended application strategy is to first use the pre-built artificial intelligence services. Next, you can use Cloud AutoML to produce custom models, which can be used with the pre-built services or on their own. Remember that you can divide a problem into specialized parts and use multiple custom models together. Finally, if you discover you need more advanced features, you can use the machine learning and artificial intelligence services to create new models.

## 2. Auto ML Vision

* Now we'll describe AutoML Vision. This is a Cloud AutoML product for image data. Cloud AutoML Vision specializes in training models for image classification. You can load the CSV file and the image files from cloud storage, or you can upload them from your local computer using Import. Training supports several file formats, including JPEG and PNG. The images can be up to 30 MB in size. They have to be converted to Base64 encoding which stores the image as a text file. The prepared file will be a TXT file or a compressed ZIP file. Service requests only recognize JPEG, PNG, and GIF files up to 1.5 MB. The trained model will work best when there are at most 100 times more images for the most common label than for the least common label. Consequently, for model performance, it is recommended that you remove very-low-frequency labels. You can label the images in the web UI or, in some cases, you can use the human labeling service offered by Google if you have more than 100 unlabeled images. To gauge your trained model's readiness, AutoML Vision creates the confusion matrix for up to 10 labels. If you have more than 10 labels, the matrix includes the 10 labels with the most incorrect predictions. The quality of Vision custom models has a lot to do with the choice of training data. Train on images with similar properties to those you intend to classify. For example, images of similar resolution, lighting, focus, and level of detail. High-confusion, low-average precision scores, or low-precision and recalled scores can indicate that your model needs additional training data or has inconsistent labels. Perfect is the enemy of good. Perfect or very high average precision scores could indicate that something is wrong in the model. The data is too easy and not varied enough. It could mean that the model might not work well beyond the test data. In this case, increase the variety of images in the prepared data set.

## 3. Auto ML NLP

* Let's move on to auto ML NLP or Natural Language Processing. Cloud auto ML natural language specializes in training models for text data. For example, if you have a set of newspaper articles, you can use the auto ML NLP service to classify if a given article is for example about sports or politics. The text to be recognized can be inline texts in the cell of the CSV file. More commonly, the text is contained in documents which are dot txt files or are compressed in zip format. The path to the cloud storage location of the document appears in the CSV file. Currently, the documents must be standard texts and do not support Unicode. The documents can be as small as one sentence or up to a maximum of a 128 kilobytes. You can have anywhere from 2-100 labels. The custom model is evaluated on average precision. That is a value from 0.5-1.0. Its formal name is the area under the precision/recall curve. A higher number indicates more accurate classification and prediction. The evaluation report also supplies confidence threshold curves which is a way of characterizing false positive classification against true positives. For models that apply one label per document, the evaluation report includes a confusion matrix. You can read more about the evaluations and how to interpret them in the online documentation. If a natural language custom model is not used for 60 days, it will be deleted. If a natural language custom model is being used, it will be deleted after six months. So you'll be required to retrain your model. The reason for this is that, training and serving methods inside cloud auto ML are frequently improved and updated. These changes are not guaranteed to be backwards compatible. They may render a custom model incompatible with the current service. High confusion and low average precision scores indicate that the prepared dataset needs additional entries or that the labels are being used inconsistently. You may be able to improve low quality evaluations for particular labels with one of these methods. Add more documents associated with those labels. In other words, they might just not be enough training data to get a good result. You also may need to increase the variety of documents by adding longer or shorter examples. Documents with different writing styles or word choice or by different authors. Finally, for labels that are not useful or have low quality, you may want to remove them altogether to increase the accuracy of the remaining labels.

## 4. Auto ML Tables

* Finally, let's go into Auto ML tabular data, tabular data tabular data is what you might find in a spreadsheet for example. While AutoML vision and NLP are for unstructured data, AutoML table is for structured data. The development of AutoML table is a collaboration with the Google brain team, while the technical details of the project haven't been released yet to the public. The team basically took the architecture search capability used for image classification and translation problems, and found a way to apply it to tabular data. Let's describe a data set where AutoML tables performs really well. The Mercari prize suggestion challenge, Mercari is Japan's biggest community powered shopping app and marketplace. Mercari created the price suggestion challenge for predicting the price of a product offered on the marketplace, so that they could give price suggestions to their sellers. Participants were given some 1.5 million rows of rich data with plenty of noise. The challenge lasted for three months and culminated in $100,000 price, over 2,000 data scientist competed for the price. This plot shows the performance of AutoML tables on the Mercari challenge for several different training times. You can see that after 24 hours of training, AutoML tables pretty much puts you on the leaderboard. Even after only one hour of training, you get to the plateau of leaders, which is extremely impressive performance on a million plus row data set with significant complexity. Compared to the 100K price for this challenge, one hour of training is just $19. Since the search process for AutoML tables is random, you might get slightly different results if you try to reproduce this performance. The easiest way to import your data into AutoML tables is through BigQuery. You can also import data using CSV files start locally or on cloud storage. One of the advantages of importing data through BigQuery is its support for a arrays and structs. Regardless, for both import sources, your data must have between 1000 and 100 million rows, between 2 and 1000 columns and be 100 gig or less in size. Once your data is imported the next step is to select the features you want to use and to specify the column you're trying to predict. In the next step of building an AutoML table model, you go through a data validation phase, the purpose of this step is to ensure you're not passing bad data to your model. This includes checking for columns that have too many null values, outliers that are skewing the distribution of a column, and columns that are not correlated to the target you're trying to predict. As you saw in the slide on AutoML tables performance on the Mercari challenge, you can train a model for a variable amount of time. You can set a training budget in node hours to cap costs, by default AutoML tables will stop training if the model isn't seeing significant performance gains anymore. Once your model is trained, you should look at the training metrics, be wary of models that are too good to be true. In this case, you likely have a data issue you'll need to resolve, for classification, the report includes metrics such as area under the curve for precision recall curve accuracy and the F1 score. Also, a confusion matrix is output along with feature importances. These two sets of metrics are particularly useful in diagnosing low-performing models. For regression models, the root mean squared error, mean absolute percentage error, and feature importances are returned among other metrics. Check the AutoML table documentation for a full list of metrics that get generated after model training. It's arguably more important to look at the performance metrics generated on the test set, to get a feel for how well your model will generalize. The same metrics generated for the training data are also available for test data. For classification models, it may be useful to set the score threshold to a value other than the default of 0.5. Increase the score threshold to make your classifier output a positive label with more confidence. Once you're happy with your model performance, you can go ahead and deploy it, you have the option of making batch or online predictions. For online predictions you can make calls using a curl command, or one of the Java, Node.js or Python APIs, the same APIs are available for batch predictions. You can make batch predictions on either BigQuery tables or CSV files. However, the BigQuery data source tables must be no larger than 100 GB. For CSV files each data source file can be no larger than 10GB, and if you include multiple files the sum of all files cannot exceed 100GB. We return to the question of when should you use BigQuery ML or AutoML versus building a custom model? The short answer is, it depends on how much time you have to build the model, and what resources you have available. This table may provide some guidance, given the low barrier of building a model in either BigQuery ML or AutoML, give either a try first. If the resulting model is not sufficient, only then should you throw more resources at it. To summarize, Cloud AutoML can build really powerful machine learning models with no coding, the models will be customized to your data. Use AutoML vision for image data, AutoML NLP for text data, and AutoML tables for structured or tabular data.

## QuizNotes

* Cloud AutoML makes use of which of the following:
	* Google's model and your data
* Which of the following are valid techniqes for improving AutoML Vision and NLP models?
	* Increase the amount of training data
	* Ensure consistent labeling
	* Inrease the diversity and complexity of data